# Home-credit-default-risk

## INTRODUCTION
- The course project is based on Home Credit Default Risk (HCDR) Kaggle competition.
- The goal is to predict whether or not a customer can be flagged as a high risk applicant.
- Final Phase will involve intensive experimentation and building deep learning models using PyTorch, a multi-headed load default system using the OOP API with combined loss function: CXE + MSE

## Feature Engineering
![image](https://github.com/user-attachments/assets/6aeb74c7-987e-4a29-9892-be586b2258df)
![image](https://github.com/user-attachments/assets/9e282585-7747-46c8-ac23-88c34a751f31)

## Model Pipeline
![image](https://github.com/user-attachments/assets/7bb87158-62e5-4188-98a6-58ba93becaa0)

## Deep learningModel Pipeline
![image](https://github.com/user-attachments/assets/7b19094a-76b9-483d-b611-41e2a4138ffd)

## Experiment Results (Traditional Models)
![image](https://github.com/user-attachments/assets/bc2fb335-aa74-4555-a3a4-a953b2da6aa0)

## Experiment Results (Neural Network)
![image](https://github.com/user-attachments/assets/5d5eaad8-cb2f-4a7f-b5ca-cd1b5444dd61)

## Conclusion
- The XGBClassifier model, tuned for optimal performance, excels across multiple evaluation metrics, including precision, recall, F1 score, accuracy, and ROC AUC score. Its ability to effectively predict both positive and negative cases, coupled with low rates of false positives and false negatives, attests to its reliability and suitability for the HCDR classification task. Overall, the results provide confidence in the model's capability to make accurate predictions and its potential for practical deployment in real-world scenarios.

## Future Scope
- Conduct a more in-depth EDA to understand the characteristics of the data.
- Explore additional feature engineering techniques to create new informative features.
- Optimize hyperparameters.
- Improving Neural nets and choosing optimum loss functions.







